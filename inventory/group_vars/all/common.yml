---
### OpenStack control plane configuration

# select OpenStack release: havana, icehouse, juno
openstack_release: juno
use_swift: true
use_ceph: false

search_domain: ".lordbusiness"
nameservers:
 - 172.17.10.22
 - 192.168.70.3
 - 192.168.70.4

### Network interface assignment
# any deviations for individual hosts should be specified in the host_vars or inventory files
primary_if: bond0.1805
private_if: bond0.1801
tunnel_if: bond0.1802

### NTP servers
ntp:
  - 0.rhel.pool.ntp.org
  - 1.rhel.pool.ntp.org
  - 2.rhel.pool.ntp.org

#neutron
neutron_ovs_bridges:
  - bridge: br-ex
    port: bond0.1805
#glance

default_store: swift

credentials_dir: /var/lib/ansible
### Pacemaker cluster
pcs_cluster_name: automation_cluster
pcs_cluster_pass: "{{ lookup('password', credentials_dir + '/credentials/pcs_cluster_pass chars=ascii_letters,digits') }}"

#database users passwords
clustercheck_db_pass: "{{ lookup('password', credentials_dir + '/credentials/clustercheck_db_pass chars=ascii_letters,digits') }}"
db_root_password: "{{ lookup('password', credentials_dir + '/credentials/db_root_password chars=ascii_letters,digits') }}"
keystone_db_pass: "{{ lookup('password', credentials_dir + '/credentials/keystone_db_pass chars=ascii_letters,digits') }}"
glance_db_pass: "{{ lookup('password', credentials_dir + '/credentials/glance_db_pass chars=ascii_letters,digits') }}"
cinder_db_pass: "{{ lookup('password', credentials_dir + '/credentials/cinder_db_pass chars=ascii_letters,digits') }}"
nova_db_pass: "{{ lookup('password', credentials_dir + '/credentials/nova_db_pass chars=ascii_letters,digits') }}"
neutron_db_pass: "{{ lookup('password', credentials_dir + '/credentials/neutron_db_pass chars=ascii_letters,digits') }}"
heat_db_pass: "{{ lookup('password', credentials_dir + '/credentials/heat_db_pass chars=ascii_letters,digits') }}"
swift_db_pass: "{{ lookup('password', credentials_dir + '/credentials/swift_db_pass chars=ascii_letters,digits') }}"

# passwords for special OpenStack users
admin_pass: "{{ lookup('password', credentials_dir + '/credentials/admin_pass chars=ascii_letters,digits') }}"
glance_pass: "{{ lookup('password', credentials_dir + '/credentials/glance_pass chars=ascii_letters,digits') }}"
cinder_pass: "{{ lookup('password', credentials_dir + '/credentials/cinder_pass chars=ascii_letters,digits') }}"
swift_pass: "{{ lookup('password', credentials_dir + '/credentials/swift_pass chars=ascii_letters,digits') }}"
neutron_pass: "{{ lookup('password', credentials_dir + '/credentials/neutron_pass chars=ascii_letters,digits') }}"
nova_pass: "{{ lookup('password', credentials_dir + '/credentials/nova_pass chars=ascii_letters,digits') }}"
heat_pass: "{{ lookup('password', credentials_dir + '/credentials/heat_pass chars=ascii_letters,digits') }}"
ceilometer_pass: "{{ lookup('password', credentials_dir + '/credentials/ceilometer_pass chars=ascii_letters,digits') }}"
keystone_admin_token: "{{ lookup('password', credentials_dir + '/credentials/keystone_admin_token chars=hexdigits') }}"

#internal VIPs
rabbit_hosts: 172.17.17.100
lb_db_vip: 172.17.17.101
keystone_vip: 172.17.17.103
glance_vip: 172.17.17.104
cinder_vip: 172.17.17.105
nova_vip: 172.17.17.106
neutron_vip: 172.17.17.107
horizon_vip: 172.17.17.108
heat_vip: 172.17.17.109
ceilometer_vip: 172.17.17.110
swift_vip: 172.17.17.111
scaleio_vip: 172.17.17.112
vip_swift_pub: 172.17.20.111
vip_keystone_pub: 172.17.20.103
vip_glance_pub: 172.17.20.104
vip_cinder_pub: 172.17.20.105
vip_nova_pub: 172.17.20.106
vip_neutron_pub: 172.17.20.107
vip_horizon_pub: 172.17.20.108
vip_heat_pub: 172.17.20.109
vip_ceilometer_pub: 172.17.20.110

### Horizon
horizon_internal_servername: vip-horizon-int.business
horizon_public_servername: vip-horizon-pub.business

# A url to make first request and get .secret_key_store generated
dashboard_first_request_url: "http://vip-horizon-pub.business/dashboard"



# VAriables not used in the current configuration

#use_galera: true
#use_cinder_nfs_volume_driver: false
#use_netapp: false
#use_netapp_copyoffload: false
# select Nova Network or Neutron
# use nfs for nova ephemeral volumes
#use_nova_nfs_backend: false
# if use_nova_shared_backend is "true", set nova_shared_volume, nova_shared_fs_type and nova_shared_fs_mount_options
#use_nova_shared_backend: "{{ use_nova_nfs_backend }}"
#use_neutron: true
#### icehouse: select ml2 and its plugins or a standalone Neutron plugin like Cisco Nexus
# use_neutron_ml2: true
# use_neutron_ovs: true
# use_neutron_l3: true
# use_lbaas: true
# use_heat: true
# use_ceilometer: true

### Keystone
# scalability tuning parameters
#keystone_rpc_conn_pool_size: 30
#keystone_rpc_thread_pool_size: 64
#keystone_database_min_pool_size: 1

### Nova
# scalability tuning parameters
#nova_rpc_conn_pool_size: 30
#nova_rpc_thread_pool_size: 64
#nova_database_min_pool_size: 1
#nova_conductor_workers: 4
#nova_osapi_workers: 4

# hypervisor features
#nova_instance_live_migration: true

# specific for neutron based network implementation
# disable security group
#nova_security_group_api: neutron
#nova_firewall_driver: neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver
#nova_firewall_driver: nova.virt.firewall.NoopFirewallDriver
#nova_ovs_bridge_mappings: "physnet1:br1"

# storage related (only use with use_ceph: true)
#nova_libvirt_images_type: raw
#nova_secret_uuid: 522e17af-794c-4db9-95ae-884c48f24b13

# Define the following parameters to use Nova with ephemeral storage on a shared volume
# For example, to use a NFS share:
#nova_shared_volume: "nfs-server.example.com:/srv/nova"
#nova_shared_fs_type: nfs4
#nova_shared_fs_mount_options: "sec=sys,defaults"

# ceilometer related
#nova_notify_on_state_change: vm_and_task_state


### Glance
# default_store: swift
# define the following parameters to use NetApp as a Glance backend
#glance_show_image_direct_url: true
#glance_show_multiple_locations: true
#glance_filesystem_store_metadata_file: /etc/glance/filesystem_store_metadata.json
# this is necessary to support NetApp copy offload
#glance_filesystem_store_file_perm: '0644'

# ceph backend settings
#default_store: rbd
#glance_rbd_user: images
#glance_rbd_pool: images
#rbd_secret_uuid: 522e17af-794c-4db9-95ae-884c48f24b13

# ceph backend settings
#cinder_rbd_user: volumes
#cinder_rbd_pool: volumes

### Ceilometer
#ceilometer_metering_secret: "{{ lookup('password', credentials_dir + '/credentials/ceilometer_metering_secret chars=hexdigits') }}"
# keep last 5 days data only (value is in secs)
#ceilometer_time_to_live: 432000


# #### swift
# # part_power = 2 ^ partition power = partition count. ( The partition is rounded up after calculation.)
# part_power: 16
# #replica couunt =  The number of times that your data will be replicated in the cluster.
# replica_count: 3
# # min_part_hours =  Minimum number of hours before a partition can be moved. This parameter increases availability of data by not moving more than one copy of a given data item within that min_part_hours amount of time.
# min_part_hours: 24
